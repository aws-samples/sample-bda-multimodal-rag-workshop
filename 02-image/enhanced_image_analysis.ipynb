{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Analysis with Amazon Bedrock Data Automation: Seeing Beyond Text\n",
    "\n",
    "This notebook expands your journey with Amazon Bedrock Data Automation (BDA) by moving beyond text-based content to explore the rich world of visual data. While document processing lays the foundation for structured extraction, image analysis represents a fundamental shift in how we interact with information that cannot be captured in text alone.\n",
    "\n",
    "As you work through this notebook, you'll build capabilities to:\n",
    "- Extract textual information embedded within images\n",
    "- Identify and analyze visual objects and logos\n",
    "- Generate comprehensive descriptions of visual content\n",
    "- Classify images according to standard taxonomies\n",
    "- Extract custom attributes from specialized image types\n",
    "\n",
    "This notebook demonstrates how to use Amazon Bedrock Data Automation (BDA) to analyze images and extract valuable insights. BDA can identify text, logos, objects, and generate summaries from images, making it powerful for various image analysis tasks.\n",
    "\n",
    "In this enhanced notebook, we'll focus on the core BDA workflow for image analysis:\n",
    "\n",
    "1. Preparing a sample image\n",
    "2. Creating a BDA project with standard and custom output configurations\n",
    "3. Processing the image with BDA\n",
    "4. Analyzing the results\n",
    "\n",
    "The setup cell below contains helper functions and initialization code. **It's collapsed by default** - you can expand it to see the details, but you don't need to understand all of it to follow the main BDA workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell contains setup code and helper functions.\n",
    "# You can expand it to see the details, but you don't need to understand all of it.\n",
    "\n",
    "import boto3\n",
    "import json\n",
    "import uuid\n",
    "import time\n",
    "import os\n",
    "import sagemaker\n",
    "from datetime import datetime\n",
    "from IPython.display import Image, clear_output, display, Markdown, HTML\n",
    "from PIL import Image as PILImage, ImageDraw\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Import all utilities from the consolidated utils\n",
    "from utils.utils import BDAImageUtils, show_business_context, download_image, ensure_bda_results_dir, visualize_detections\n",
    "\n",
    "# Initialize our utility class\n",
    "bda_utils = BDAImageUtils()\n",
    "\n",
    "# Display comprehensive business context for image analysis\n",
    "show_business_context(\"image_analysis_complete\")\n",
    "\n",
    "print(f\"Setup complete. BDA utilities initialized for region: {bda_utils.current_region}\")\n",
    "print(f\"Using S3 bucket: {bda_utils.bucket_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Industry Applications\n",
    "\n",
    "As you work through this notebook, consider how image analysis could transform workflows in your specific domain:\n",
    "\n",
    "**Retail**: How would automatic product detection, logo identification, and attribute extraction from product images change your catalog management and customer experiences?\n",
    "\n",
    "**Marketing & Advertising**: What if your campaigns could automatically measure brand presence, analyze ad composition, and extract text from visual promotional materials?\n",
    "\n",
    "**Manufacturing**: How could visual quality inspection, defect detection, and component identification from product images transform your production processes?\n",
    "\n",
    "**Healthcare**: What new possibilities would emerge from analyzing medical images, identifying visual indicators, and extracting measurements from diagnostic visuals?\n",
    "\n",
    "**Your Industry**: What types of images are critical to your organization's workflows? What insights within these images would provide the most business value if automatically extracted?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Prepare Sample Image\n",
    "\n",
    "First, we'll download a sample advertisement image and upload it to S3 for processing with BDA. This image contains text, logos, and other elements that BDA can analyze.\n",
    "\n",
    "The image will be stored in an S3 bucket that BDA can access. This is a required step as BDA needs to read the image from S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download sample image\n",
    "sample_image = 'travel.png'\n",
    "source_url = f'https://d1xvhy22zmw77y.cloudfront.net/tmp/{sample_image}'\n",
    "\n",
    "# Download the image locally using enhanced download function\n",
    "local_path = download_image(source_url, sample_image) or bda_utils.download_image(source_url, sample_image)\n",
    "\n",
    "# Display the image\n",
    "display(Image(sample_image, width=800))\n",
    "\n",
    "# Upload to S3\n",
    "s3_key = f'{bda_utils.data_prefix}/{sample_image}'\n",
    "s3_uri = bda_utils.upload_to_s3(sample_image, s3_key)\n",
    "print(f\"Uploaded image to S3: {s3_uri}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Define BDA Configuration\n",
    "\n",
    "Before creating a BDA project, we need to define both standard and custom output configurations. These configurations determine what information BDA will extract from the image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BDA Configuration Details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standard Output Configuration\n",
    "\n",
    "The standard output configuration includes:\n",
    "\n",
    "- **Text Detection**: Extract text from the image with bounding boxes\n",
    "- **Logo Detection**: Identify brand logos with bounding boxes\n",
    "- **Image Summary**: Generate a descriptive summary of the image\n",
    "- **IAB Categories**: Classify the image into Internet Advertising Bureau categories\n",
    "\n",
    "### Custom Output Configuration (Blueprint)\n",
    "\n",
    "We'll also create a custom blueprint to extract specific information about the advertisement:\n",
    "\n",
    "- **Product Type**: What product or service is being advertised\n",
    "- **Product Count**: Number of products visible in the image\n",
    "- **Scene Location**: Setting or location of the scene\n",
    "- **Image Background**: Type of background in the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display business context for custom blueprints\n",
    "show_business_context(\"custom_blueprints\")\n",
    "\n",
    "# Define the custom blueprint for image analysis\n",
    "# This blueprint defines the schema for extracting specific information from advertisement images\n",
    "blueprint = {\n",
    "    # Top-level class and description define the overall purpose of the blueprint\n",
    "    \"class\": \"Ad scene analysis\",  # Name of the blueprint class\n",
    "    \"description\": \"This blueprint is designed to extract key information from an image depicting an Ad scene.\",\n",
    "    \n",
    "    # Definitions section contains reusable property groups that can be referenced elsewhere\n",
    "    \"definitions\": {\n",
    "        \"ProductDetails\": {  # Define a reusable group of properties for product information\n",
    "            \"properties\": {\n",
    "                \"product_type\": {  # Extract the type of product being advertised\n",
    "                  \"type\": \"string\",  # Expect a string response\n",
    "                  \"inferenceType\": \"inferred\",  # This will be inferred by AI, not extracted directly\n",
    "                  \"instruction\": \"What is the primary product or service being advertised, e.g., Clothing, Electronics, Food & Beverage, etc.?\"\n",
    "                },\n",
    "                \"product_count\": {  # Count the number of products visible\n",
    "                    \"type\": \"number\",  # Expect a numeric response\n",
    "                    \"inferenceType\": \"inferred\",\n",
    "                    \"instruction\": \"Count the number of product visible in the image.\"\n",
    "                },\n",
    "                \"scene_location\": {  # Describe the setting of the advertisement\n",
    "                  \"type\": \"string\",\n",
    "                  \"inferenceType\": \"inferred\",\n",
    "                  \"instruction\": \"Describe the setting or location of the scene, such as the type of field or surrounding buildings.\"\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    \n",
    "    # Root-level properties to extract from the image\n",
    "    \"properties\": {\n",
    "        \"product_details\": {  # Use the ProductDetails definition from above\n",
    "            \"instruction\": \"Detailed information about the advertised product, including its category, name, and placement within the image.\",\n",
    "            \"$ref\": \"#/definitions/ProductDetails\"  # Reference to the definition above\n",
    "        },\n",
    "        \"image_background\": {  # Additional property at the root level\n",
    "            \"type\": \"string\",\n",
    "            \"inferenceType\": \"inferred\",\n",
    "            \"instruction\": \"What is the background of the ad image? For example, \\u0027Solid color\\u0027, \\u0027Natural landscape\\u0027, \\u0027Indoor\\u0027, \\u0027Urban\\u0027, \\u0027Abstract\\u0027\"\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Generate a unique blueprint name to avoid naming conflicts\n",
    "unique_id = str(uuid.uuid4())[0:6]\n",
    "blueprint_name = f\"bda-image-custom-blueprint-{unique_id}\"\n",
    "\n",
    "print(f\"Creating blueprint with name: {blueprint_name}\")\n",
    "\n",
    "# Create the blueprint in BDA\n",
    "try:\n",
    "    bp_response = bda_utils.bda_client.create_blueprint(\n",
    "        blueprintName=blueprint_name,\n",
    "        type='IMAGE',  # Specify this is for image analysis\n",
    "        blueprintStage='DEVELOPMENT',  # Use development stage for workshop\n",
    "        schema=json.dumps(blueprint),  # Convert blueprint dict to JSON string\n",
    "    )\n",
    "    \n",
    "    blueprint_arn = bp_response.get(\"blueprint\", {}).get(\"blueprintArn\")\n",
    "    print(f\"Blueprint created successfully with ARN: {blueprint_arn}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error creating blueprint: {e}\")\n",
    "    blueprint_arn = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Create BDA Project\n",
    "\n",
    "Now we'll create a BDA project with our standard and custom output configurations. The project stores the configuration settings that will be used to process images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project Architecture for Image Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Parameters for `create_data_automation_project` API:\n",
    "\n",
    "- **projectName**: A unique name for the project\n",
    "- **projectDescription**: A description of the project's purpose\n",
    "- **projectStage**: The stage of the project (DEVELOPMENT or LIVE)\n",
    "- **standardOutputConfiguration**: The standard output settings\n",
    "- **customOutputConfiguration**: The custom blueprint configuration\n",
    "\n",
    "The project ARN returned by this API will be used when invoking BDA to process images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show business context for project architecture\n",
    "show_business_context(\"project_architecture\")\n",
    "\n",
    "# Create a BDA project with both standard and custom output configurations\n",
    "print(\"Creating BDA project for image analysis...\")\n",
    "response = bda_utils.bda_client.create_data_automation_project(\n",
    "    projectName=f'bda-workshop-image-project-{str(uuid.uuid4())[0:4]}',\n",
    "    projectDescription='BDA workshop image sample project',\n",
    "    projectStage='DEVELOPMENT',\n",
    "    standardOutputConfiguration={\n",
    "        'image': {\n",
    "            'extraction': {\n",
    "                'category': {\n",
    "                    'state': 'ENABLED',\n",
    "                    'types': [\n",
    "                        'TEXT_DETECTION',  # Extract text from the image\n",
    "                        'LOGOS'            # Identify brand logos\n",
    "                    ]\n",
    "                },\n",
    "                'boundingBox': {\n",
    "                    'state': 'ENABLED'     # Include bounding boxes for detected elements\n",
    "                }\n",
    "            },\n",
    "            'generativeField': {\n",
    "                'state': 'ENABLED',\n",
    "                'types': [\n",
    "                    'IMAGE_SUMMARY',       # Generate a summary of the image\n",
    "                    'IAB'                  # Classify into IAB categories\n",
    "                ]\n",
    "            }\n",
    "        },\n",
    "    },\n",
    "    customOutputConfiguration={\n",
    "        'blueprints': [\n",
    "            {\n",
    "                'blueprintArn': blueprint_arn,\n",
    "                'blueprintStage': 'DEVELOPMENT'\n",
    "            },\n",
    "        ]\n",
    "    },\n",
    ")\n",
    "\n",
    "# Get the project ARN\n",
    "image_project_arn = response.get(\"projectArn\")\n",
    "print(f\"BDA project created with ARN: {image_project_arn}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Process Image with BDA\n",
    "\n",
    "Now we'll use the `invoke_data_automation_async` API to process our image with BDA. This API starts an asynchronous job to analyze the image and extract insights based on our project configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show business context for processing pipeline\n",
    "show_business_context(\"processing_pipeline\")\n",
    "\n",
    "# Invoke BDA to process the image\n",
    "print(f\"Processing image: {s3_uri}\")\n",
    "print(f\"Results will be stored at: s3://{bda_utils.bucket_name}/{bda_utils.output_prefix}\")\n",
    "\n",
    "# Call the invoke_data_automation_async API\n",
    "response = bda_utils.bda_runtime_client.invoke_data_automation_async(\n",
    "    inputConfiguration={\n",
    "        's3Uri': s3_uri  # The S3 location of our image\n",
    "    },\n",
    "    outputConfiguration={\n",
    "        's3Uri': f's3://{bda_utils.bucket_name}/{bda_utils.output_prefix}'  # Where to store results\n",
    "    },\n",
    "    dataAutomationConfiguration={\n",
    "        'dataAutomationProjectArn': image_project_arn,  # The project we created\n",
    "        'stage': 'DEVELOPMENT'                          # Must match the project stage\n",
    "    },\n",
    "    dataAutomationProfileArn=f'arn:aws:bedrock:{bda_utils.current_region}:{bda_utils.account_id}:data-automation-profile/us.data-automation-v1'\n",
    ")\n",
    "\n",
    "# Get the invocation ARN\n",
    "invocation_arn = response['invocationArn']\n",
    "print(f\"Invocation ARN: {invocation_arn}\")\n",
    "\n",
    "# Wait for processing to complete\n",
    "status_response = bda_utils.wait_for_completion(\n",
    "    get_status_function=bda_utils.bda_runtime_client.get_data_automation_status,\n",
    "    status_kwargs={'invocationArn': invocation_arn},\n",
    "    completion_states=['Success'],\n",
    "    error_states=['ClientError', 'ServiceError'],\n",
    "    status_path_in_response='status',\n",
    "    max_iterations=15,\n",
    "    delay=10\n",
    ")\n",
    "\n",
    "# Check if processing was successful\n",
    "if status_response['status'] == 'Success':\n",
    "    output_config_uri = status_response.get(\"outputConfiguration\", {}).get(\"s3Uri\")\n",
    "    print(f\"\\nImage processing completed successfully!\")\n",
    "    print(f\"Output configuration: {output_config_uri}\")\n",
    "else:\n",
    "    print(f\"\\nImage processing failed with status: {status}\")\n",
    "    if 'error_message' in status_response:\n",
    "        print(f\"Error message: {status_response['error_message']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Analyze BDA Results\n",
    "\n",
    "Finally, we'll retrieve and analyze the results from BDA. We'll break this analysis into several focused sections:\n",
    "\n",
    "1. Job metadata and overview \n",
    "2. Image summary and classification\n",
    "3. Visual elements detection (text, logos)\n",
    "4. Custom analysis and practical applications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Job Metadata and Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show business context for business applications\n",
    "show_business_context(\"business_applications\")\n",
    "\n",
    "# Load job metadata\n",
    "config_data = bda_utils.read_json_from_s3(output_config_uri)\n",
    "\n",
    "# Get standard output path\n",
    "standard_output_path = config_data[\"output_metadata\"][0][\"segment_metadata\"][0][\"standard_output_path\"]\n",
    "standard_output = bda_utils.read_json_from_s3(standard_output_path)\n",
    "\n",
    "# Get custom output path\n",
    "custom_output_path = config_data[\"output_metadata\"][0][\"segment_metadata\"][0][\"custom_output_path\"]\n",
    "custom_output = bda_utils.read_json_from_s3(custom_output_path)\n",
    "\n",
    "# Display job metadata\n",
    "print(\"=== Job Information ===\")\n",
    "print(f\"Job ID: {config_data.get('job_id', 'N/A')}\")\n",
    "print(f\"Input type: {config_data.get('input_type', 'N/A')}\")\n",
    "print(f\"Asset count: {len(config_data.get('output_metadata', []))}\")\n",
    "\n",
    "# Display image metadata\n",
    "print(\"\\n=== Image Metadata ===\")\n",
    "metadata = standard_output[\"metadata\"]\n",
    "print(f\"Width: {metadata.get('image_width_pixels', 'N/A')} pixels\")\n",
    "print(f\"Height: {metadata.get('image_height_pixels', 'N/A')} pixels\")\n",
    "print(f\"Format: {metadata.get('image_format', 'N/A')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Image Summary and Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show business context for image classification\n",
    "show_business_context(\"image_classification\")\n",
    "\n",
    "# Display image summary\n",
    "print(\"=== Image Summary ===\")\n",
    "print(standard_output[\"image\"][\"summary\"])\n",
    "\n",
    "# Display IAB categories\n",
    "print(\"\\n=== IAB Categories ===\")\n",
    "for iab in standard_output[\"image\"][\"iab_categories\"]:\n",
    "    # Check if confidence key exists before trying to access it\n",
    "    if 'confidence' in iab:\n",
    "        print(f\"- {iab['category']} (Confidence: {iab['confidence']:.2f})\")\n",
    "    else:\n",
    "        print(f\"- {iab['category']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Visual Elements Detection (Text & Logos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show business context for text extraction\n",
    "show_business_context(\"text_in_image\")\n",
    "\n",
    "# Display detected text\n",
    "print(\"=== Detected Text ===\")\n",
    "if \"text_lines\" in standard_output[\"image\"]:\n",
    "    for i, txt in enumerate(standard_output[\"image\"][\"text_lines\"]):\n",
    "        print(f\"{i+1}. {txt['text']}\")\n",
    "else:\n",
    "    print(\"No text detected\")\n",
    "\n",
    "# Display detected logos\n",
    "print(\"\\n=== Detected Logos ===\")\n",
    "if \"logos\" in standard_output[\"image\"]:\n",
    "    for i, logo in enumerate(standard_output[\"image\"][\"logos\"]):\n",
    "        print(f\"{i+1}. {logo.get('name', 'Unknown logo')}\")\n",
    "else:\n",
    "    print(\"No logos detected\")\n",
    "    \n",
    "# Use our enhanced visualization function to show detections\n",
    "visualization = visualize_detections(sample_image, standard_output)\n",
    "visualization.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4 Custom Analysis and Practical Applications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create bda-results directory if it doesn't exist\n",
    "ensure_bda_results_dir()\n",
    "\n",
    "# Combine standard and custom outputs into a single result\n",
    "combined_result = {\n",
    "    \"standard_output\": standard_output,\n",
    "    \"custom_output\": custom_output\n",
    "}\n",
    "\n",
    "# Save the combined result to the bda-results directory\n",
    "with open('../bda-results/image_result.json', 'w') as f:\n",
    "    json.dump(combined_result, f)\n",
    "    \n",
    "print(f\"Saved image results to: ../bda-results/image_result.json\")\n",
    "\n",
    "# Display custom analysis results\n",
    "print(\"\\n=== Custom Analysis ===\")\n",
    "product_details = custom_output[\"inference_result\"][\"product_details\"]\n",
    "print(f\"Product Type: {product_details['product_type']}\")\n",
    "print(f\"Product Count: {product_details['product_count']}\")\n",
    "print(f\"Scene Location: {product_details['scene_location']}\")\n",
    "print(f\"Image Background: {custom_output['inference_result']['image_background']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook, we demonstrated how to use Amazon Bedrock Data Automation (BDA) to analyze images and extract valuable insights. We covered the key steps in the BDA workflow and explored the powerful capabilities BDA offers for visual content analysis.\n",
    "\n",
    "Through this hands-on exercise, we've seen how BDA can transform unstructured visual content into structured, actionable data that can power intelligent applications across various domains.\n",
    "\n",
    "The journey from document processing to image analysis represents a significant expansion of our multimodal capabilities, laying the groundwork for even more advanced modalities in the upcoming modules."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
