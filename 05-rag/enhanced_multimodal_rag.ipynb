{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multimodal RAG with Amazon Bedrock Data Automation\n",
    "\n",
    "![BDA RAG Solution](../../static/bda-rag-solution.png)\n",
    "\n",
    "This notebook demonstrates how to build a Multimodal Retrieval-Augmented Generation (RAG) application using Amazon Bedrock Data Automation (BDA) and Bedrock Knowledge Bases (KB). The application can analyze and generate insights from multiple data modalities, including documents, images, audio, and video."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Configuration\n",
    "\n",
    "Let's start by setting up the necessary dependencies and AWS clients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install \"boto3>=1.37.4\" s3fs tqdm retrying packaging --upgrade -qq\n",
    "\n",
    "import boto3\n",
    "import json\n",
    "import uuid\n",
    "import time\n",
    "import os\n",
    "import random\n",
    "import sagemaker\n",
    "import logging\n",
    "import mimetypes\n",
    "from botocore.exceptions import ClientError\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(format='[%(asctime)s] p%(process)s {%(filename)s:%(lineno)d} %(levelname)s - %(message)s', level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Initialize AWS clients and session\n",
    "session = sagemaker.Session()\n",
    "default_bucket = session.default_bucket()\n",
    "\n",
    "sts_client = boto3.client('sts')\n",
    "account_id = sts_client.get_caller_identity()[\"Account\"]\n",
    "region_name = boto3.session.Session().region_name\n",
    "\n",
    "s3_client = boto3.client('s3')\n",
    "bedrock_agent_client = boto3.client('bedrock-agent')\n",
    "bedrock_agent_runtime_client = boto3.client('bedrock-agent-runtime')\n",
    "\n",
    "print(f\"‚úÖ Setup complete!\")\n",
    "print(f\"üìç Using AWS region: {region_name}\")\n",
    "print(f\"ü™£ Using default S3 bucket: {default_bucket}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Prepare Data for Multimodal Knowledge Base\n",
    "\n",
    "In this step, we'll prepare our data sources for the knowledge base. We have two options:\n",
    "\n",
    "1. **Use BDA Output Files** from previous notebooks in this workshop (document, image, audio, video analysis)\n",
    "2. **Use Sample Files** as a fallback if no BDA outputs are available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import our BDARAGUtils class\n",
    "from utils.utils import BDARAGUtils\n",
    "\n",
    "# Create a directory for sample files\n",
    "os.makedirs('examples', exist_ok=True)\n",
    "\n",
    "# Define the S3 prefix for our dataset\n",
    "s3_prefix = 'bda/dataset/'\n",
    "\n",
    "# Check for and upload BDA outputs from previous notebooks\n",
    "bda_outputs_exist, bucket_name_kb = BDARAGUtils.check_and_upload_bda_outputs(s3_client, region_name=region_name)\n",
    "\n",
    "# If no BDA outputs found, download and use sample files instead\n",
    "if not bda_outputs_exist:\n",
    "    print(\"\\nüì• No BDA output files found from previous modules. Downloading sample files instead...\")\n",
    "    BDARAGUtils.download_sample_files(output_dir='./examples')\n",
    "    \n",
    "    # Upload the sample files to S3\n",
    "    print(\"\\n‚¨ÜÔ∏è Uploading sample files to S3...\")\n",
    "    for file_name in os.listdir('./examples/'):\n",
    "        local_path = os.path.join('./examples/', file_name)\n",
    "        s3_key = s3_prefix + file_name\n",
    "        s3_client.upload_file(local_path, bucket_name_kb, s3_key)\n",
    "        print(f\"  ‚úì Uploaded {file_name} to s3://{bucket_name_kb}/{s3_key}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Verify Data in S3\n",
    "\n",
    "Let's check our S3 bucket to confirm the files that will be used in our knowledge base."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display information about the S3 bucket\n",
    "print(f\"ü™£ Using S3 bucket: {bucket_name_kb}\")\n",
    "print(f\"üìÇ S3 prefix: {s3_prefix}\")\n",
    "\n",
    "# List files in the bucket/prefix\n",
    "response = s3_client.list_objects_v2(Bucket=bucket_name_kb, Prefix=s3_prefix)\n",
    "if 'Contents' in response:\n",
    "    print(\"\\nüìÑ Files in the bucket:\")\n",
    "    for obj in response['Contents']:\n",
    "        key = obj['Key']\n",
    "        filename = key.split('/')[-1]\n",
    "        size_kb = obj['Size'] / 1024\n",
    "        print(f\"  - {filename} ({size_kb:.1f} KB)\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è No files found in the bucket for the specified prefix.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Create Multimodal Knowledge Base\n",
    "\n",
    "Now we'll create a Knowledge Base that can handle our multimodal data using BDARAGUtils."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a timestamp-based suffix for unique resource names\n",
    "timestamp_str = time.strftime(\"%Y%m%d%H%M%S\", time.localtime(time.time()))[-7:]\n",
    "kb_suffix = f\"{timestamp_str}\"\n",
    "\n",
    "# Define Knowledge Base parameters\n",
    "knowledge_base_name = f\"multimodal-rag-kb-{kb_suffix}\"\n",
    "knowledge_base_description = \"Multimodal RAG Knowledge Base for the BDA Workshop\"\n",
    "\n",
    "# Define data sources\n",
    "data_sources = [{\n",
    "    \"type\": \"S3\", \n",
    "    \"bucket_name\": bucket_name_kb,\n",
    "    \"inclusionPrefixes\": [s3_prefix]\n",
    "}]\n",
    "\n",
    "# Create the Knowledge Base\n",
    "print(f\"üèóÔ∏è Creating Knowledge Base: {knowledge_base_name}\")\n",
    "print(\"This may take several minutes to complete...\")\n",
    "\n",
    "try:\n",
    "    knowledge_base = BDARAGUtils(\n",
    "        kb_name=knowledge_base_name,\n",
    "        kb_description=knowledge_base_description,\n",
    "        data_sources=data_sources,\n",
    "        multi_modal=True,\n",
    "        # If using BDA output files, we don't need BDA as the parser\n",
    "        # If using raw files, we need BDA as the parser\n",
    "        parser=None if bda_outputs_exist else 'BEDROCK_DATA_AUTOMATION',\n",
    "        chunking_strategy=\"FIXED_SIZE\",\n",
    "        suffix=kb_suffix\n",
    "    )\n",
    "    \n",
    "    knowledge_base.setup_resources()\n",
    "    \n",
    "    kb_id = knowledge_base.get_knowledge_base_id()\n",
    "    print(f\"\\nüéâ Knowledge Base created successfully!\")\n",
    "    print(f\"üìå Knowledge Base ID: {kb_id}\")\n",
    "except Exception as e:\n",
    "    print(f\"\\n‚ùå Error creating Knowledge Base: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Start Data Ingestion\n",
    "\n",
    "Now that we've created our Knowledge Base, we need to ingest the multimodal data. This process transforms our files into vector embeddings that can be efficiently searched."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"‚è≥ Starting data ingestion...\")\n",
    "print(\"This process may take several minutes depending on the amount and size of data.\")\n",
    "\n",
    "try:\n",
    "    # Start the ingestion job\n",
    "    knowledge_base.start_ingestion_job()\n",
    "    print(\"\\n‚úÖ Data ingestion completed successfully!\")\n",
    "except Exception as e:\n",
    "    print(f\"\\n‚ùå Error during data ingestion: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Query the Knowledge Base\n",
    "\n",
    "Now that our data is ingested, we can query the Knowledge Base using natural language. We'll use the `query_knowledge_base` method which makes actual AWS API calls to retrieve information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_kb(query, model_id=\"amazon.nova-micro-v1:0\", num_results=5):\n",
    "    \"\"\"\n",
    "    Query the knowledge base using real AWS API calls and display the results\n",
    "    \n",
    "    Args:\n",
    "        query: The query to send to the knowledge base\n",
    "        model_id: The foundation model to use for generating the response\n",
    "        num_results: Number of results to retrieve from the knowledge base\n",
    "    \"\"\"\n",
    "    print(f\"üîç Query: {query}\")\n",
    "    print(f\"‚è≥ Processing...\")\n",
    "    \n",
    "    try:\n",
    "        # Use the real AWS API to query the knowledge base\n",
    "        response = knowledge_base.query_knowledge_base(\n",
    "            query=query,\n",
    "            model_id=model_id,\n",
    "            num_results=num_results\n",
    "        )\n",
    "        \n",
    "        # Print the response text\n",
    "        if response and 'output' in response and 'text' in response['output']:\n",
    "            print(\"\\nüìù Response:\")\n",
    "            print(response['output']['text'])\n",
    "        else:\n",
    "            print(\"\\n‚ùå No valid response received\")\n",
    "            \n",
    "        # Return the raw response for further inspection if needed\n",
    "        return response\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ùå Error querying Knowledge Base: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query 1: Audio Content\n",
    "\n",
    "Let's start by querying information from the audio content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query about the podcast content\n",
    "audio_query = \"What key topics were discussed in the AWS podcast?\"\n",
    "\n",
    "audio_response = query_kb(audio_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query 2: Visual Content\n",
    "\n",
    "Now let's query information from visual content (images or video frames)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query about visual content\n",
    "visual_query = \"What are the main components shown in the BDA architecture diagram?\"\n",
    "\n",
    "visual_response = query_kb(visual_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query 3: Document Content\n",
    "\n",
    "Let's explore information from document content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query about document content\n",
    "document_query = \"What are the key features of Amazon Bedrock according to the documentation?\"\n",
    "\n",
    "document_response = query_kb(document_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query 4: Cross-Modal Integration\n",
    "\n",
    "Now let's ask a question that requires integrating information across multiple modalities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query requiring cross-modal integration\n",
    "cross_modal_query = \"Compare how Amazon Bedrock is described in the documentation versus the podcast and visual materials.\"\n",
    "\n",
    "cross_modal_response = query_kb(\n",
    "    query=cross_modal_query,\n",
    "    num_results=8  # Increase results to capture information from multiple modalities\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Clean Up Resources (Optional)\n",
    "\n",
    "When you're done with the Knowledge Base, you can clean up the resources to avoid incurring additional costs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment and run this cell to clean up resources when you're done\n",
    "# \n",
    "# print(\"üßπ Cleaning up resources...\")\n",
    "# \n",
    "# try:\n",
    "#     # Delete the Knowledge Base and associated resources\n",
    "#     knowledge_base.delete_kb(delete_s3_bucket=False, delete_iam_roles_and_policies=True)\n",
    "#     print(\"\\n‚úÖ Knowledge Base deleted successfully.\")\n",
    "#     \n",
    "#     # Delete any temporary files\n",
    "#     for temp_file in os.listdir('./examples') if os.path.exists('./examples') else []:\n",
    "#         os.remove(os.path.join('./examples', temp_file))\n",
    "#     \n",
    "#     print(\"\\nüéâ Cleanup completed!\")\n",
    "# except Exception as e:\n",
    "#     print(f\"\\n‚ùå Error during cleanup: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook, we demonstrated how to build a Multimodal RAG application using Amazon Bedrock Data Automation and Bedrock Knowledge Bases. We covered the key steps:\n",
    "\n",
    "1. **Data Preparation**: We checked for existing BDA outputs or downloaded sample files\n",
    "2. **Knowledge Base Creation**: We created a Knowledge Base using real AWS API calls\n",
    "3. **Data Ingestion**: We ingested our multimodal data into the Knowledge Base\n",
    "4. **Querying**: We queried the Knowledge Base across different modalities using real AWS API calls\n",
    "\n",
    "This approach allows you to build powerful multimodal applications that can extract insights from different data types (documents, images, audio, and video) and provide unified access through natural language queries."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
