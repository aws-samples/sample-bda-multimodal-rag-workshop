{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# From Insights to Intelligence: Multimodal RAG with Amazon Bedrock\n",
        "\n",
        "This notebook demonstrates how to build a Multimodal Retrieval-Augmented Generation (RAG) application using Amazon Bedrock Data Automation (BDA) and Bedrock Knowledge Bases (KB). The application can analyze and generate insights from multiple data modalities, including documents, images, audio, and video."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup and Configuration\n",
        "\n",
        "Let's start by setting up the necessary dependencies and AWS clients."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install \"boto3>=1.37.4\" s3fs tqdm retrying packaging --upgrade -qq\n",
        "\n",
        "import boto3\n",
        "import json\n",
        "import uuid\n",
        "import time\n",
        "import os\n",
        "import random\n",
        "import sagemaker\n",
        "import logging\n",
        "import mimetypes\n",
        "from botocore.exceptions import ClientError\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Import utils and access the business context function\n",
        "from utils.utils import BDARAGUtils\n",
        "\n",
        "# Create utility instance to use its methods\n",
        "rag_utils = BDARAGUtils()\n",
        "\n",
        "# Display comprehensive business context for RAG\n",
        "rag_utils.show_business_context(\"rag_complete\")\n",
        "\n",
        "# Configure logging\n",
        "logging.basicConfig(format='[%(asctime)s] p%(process)s {%(filename)s:%(lineno)d} %(levelname)s - %(message)s', level=logging.INFO)\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# Initialize AWS clients and session\n",
        "session = sagemaker.Session()\n",
        "default_bucket = session.default_bucket()\n",
        "\n",
        "sts_client = boto3.client('sts')\n",
        "account_id = sts_client.get_caller_identity()[\"Account\"]\n",
        "region_name = boto3.session.Session().region_name\n",
        "\n",
        "s3_client = boto3.client('s3')\n",
        "bedrock_agent_client = boto3.client('bedrock-agent')\n",
        "bedrock_agent_runtime_client = boto3.client('bedrock-agent-runtime')\n",
        "\n",
        "print(f\"Setup complete!\")\n",
        "print(f\"Using AWS region: {region_name}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Prepare Data for Multimodal Knowledge Base\n",
        "\n",
        "In this step, we'll prepare our data sources for the knowledge base. We have two options:\n",
        "\n",
        "1. **Use BDA Output Files** from previous notebooks in this workshop (document, image, audio, video analysis)\n",
        "2. **Use Sample Files** as a fallback if no BDA outputs are available"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import our BDARAGUtils class\n",
        "from utils.utils import BDARAGUtils\n",
        "\n",
        "# Create a directory for sample files\n",
        "os.makedirs('examples', exist_ok=True)\n",
        "\n",
        "# Define the S3 prefix for our dataset\n",
        "s3_prefix = 'bda/dataset/'\n",
        "\n",
        "# Check for and upload BDA outputs from previous notebooks\n",
        "bda_outputs_exist, bucket_name_kb = BDARAGUtils.check_and_upload_bda_outputs(s3_client, region_name=region_name)\n",
        "\n",
        "# If no BDA outputs found, download and use sample files instead\n",
        "if not bda_outputs_exist:\n",
        "    print(\"\\nNo BDA output files found from previous modules. Downloading sample files instead...\")\n",
        "    BDARAGUtils.download_sample_files(output_dir='./examples')\n",
        "    \n",
        "    # Upload the sample files to S3\n",
        "    print(\"\\nUploading sample files to S3...\")\n",
        "    for file_name in os.listdir('./examples/'):\n",
        "        local_path = os.path.join('./examples/', file_name)\n",
        "        s3_key = s3_prefix + file_name\n",
        "        s3_client.upload_file(local_path, bucket_name_kb, s3_key)\n",
        "        print(f\"Uploaded {file_name} to s3://{bucket_name_kb}/{s3_key}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Create Multimodal Knowledge Base\n",
        "\n",
        "Now we'll create a Knowledge Base that can handle our multimodal data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Display business context for Knowledge Base creation\n",
        "rag_utils.show_business_context(\"knowledge_base\")\n",
        "\n",
        "# Create a timestamp-based suffix for unique resource names\n",
        "timestamp_str = time.strftime(\"%Y%m%d%H%M%S\", time.localtime(time.time()))[-7:]\n",
        "kb_suffix = f\"{timestamp_str}\"\n",
        "\n",
        "# Define Knowledge Base parameters\n",
        "knowledge_base_name = f\"multimodal-rag-kb-{kb_suffix}\"\n",
        "knowledge_base_description = \"Multimodal RAG Knowledge Base for the BDA Workshop\"\n",
        "\n",
        "# Define data sources\n",
        "data_sources = [{\n",
        "    \"type\": \"S3\", \n",
        "    \"bucket_name\": bucket_name_kb,\n",
        "    \"inclusionPrefixes\": [s3_prefix]\n",
        "}]\n",
        "\n",
        "# Create the Knowledge Base\n",
        "print(f\"üèóÔ∏è Creating Knowledge Base: {knowledge_base_name}\")\n",
        "print(\"This may take several minutes to complete...\")\n",
        "\n",
        "try:\n",
        "    knowledge_base = BDARAGUtils(\n",
        "        kb_name=knowledge_base_name,\n",
        "        kb_description=knowledge_base_description,\n",
        "        data_sources=data_sources,\n",
        "        multi_modal=True,\n",
        "        # If using BDA output files, we don't need BDA as the parser\n",
        "        # If using raw files, we need BDA as the parser\n",
        "        parser=None if bda_outputs_exist else 'BEDROCK_DATA_AUTOMATION',\n",
        "        chunking_strategy=\"FIXED_SIZE\",\n",
        "        suffix=kb_suffix\n",
        "    )\n",
        "    \n",
        "    knowledge_base.setup_resources()\n",
        "    \n",
        "    kb_id = knowledge_base.get_knowledge_base_id()\n",
        "    print(f\"\\nKnowledge Base created successfully!\")\n",
        "    print(f\"Knowledge Base ID: {kb_id}\")\n",
        "except Exception as e:\n",
        "    print(f\"\\nError creating Knowledge Base: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Start Data Ingestion\n",
        "\n",
        "Now that we've created our Knowledge Base, we need to ingest the multimodal data. This process transforms our files into vector embeddings that can be efficiently searched."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "print(\"Starting data ingestion...\")\n",
        "print(\"This process may take several minutes depending on the amount and size of data.\")\n",
        "\n",
        "# Display business context for data ingestion process\n",
        "rag_utils.show_business_context(\"data_ingestion\")\n",
        "\n",
        "try:\n",
        "    # Start the ingestion job\n",
        "    knowledge_base.start_ingestion_job()\n",
        "    print(\"\\nData ingestion completed successfully!\")\n",
        "except Exception as e:\n",
        "    print(f\"\\nError during data ingestion: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Query the Knowledge Base\n",
        "\n",
        "Now that our data is ingested, we can query the Knowledge Base using natural language. We'll use Amazon Bedrock's RetrieveAndGenerate API."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Display business context for semantic search and querying\n",
        "rag_utils.show_business_context(\"semantic_search\")\n",
        "\n",
        "def query_kb(query, model_id=\"amazon.nova-micro-v1:0\", num_results=5):\n",
        "    \"\"\"\n",
        "    Query the knowledge base using real AWS API calls and display the results\n",
        "    \n",
        "    Args:\n",
        "        query: The query to send to the knowledge base\n",
        "        model_id: The foundation model to use for generating the response\n",
        "        num_results: Number of results to retrieve from the knowledge base\n",
        "    \"\"\"\n",
        "    print(f\"üîç Query: {query}\")\n",
        "    print(f\"‚è≥ Processing...\")\n",
        "    \n",
        "    try:\n",
        "        # Use the real AWS API to query the knowledge base\n",
        "        response = knowledge_base.query_knowledge_base(\n",
        "            query=query,\n",
        "            model_id=model_id,\n",
        "            num_results=num_results\n",
        "        )\n",
        "            \n",
        "        # Return the raw response\n",
        "        return response\n",
        "    \n",
        "    except Exception as e:\n",
        "        print(f\"\\nError querying Knowledge Base: {e}\")\n",
        "        return None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Query 1: Audio Content\n",
        "\n",
        "Let's start by querying information from the audio content."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Query about the audio content\n",
        "audio_query = \"What key topics were discussed in the AWS podcast?\"\n",
        "\n",
        "audio_response = query_kb(audio_query)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Query 2: Visual Content\n",
        "\n",
        "Now let's query information from the image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Query about visual content\n",
        "visual_query = \"What were the priducts shown at the Airport?\"\n",
        "\n",
        "visual_response = query_kb(visual_query)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Query 3: Document Content\n",
        "\n",
        "Let's explore information from document content."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Query about document content\n",
        "document_query = \"What are the key callouts from the treasury statement?\"\n",
        "\n",
        "document_response = query_kb(document_query)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Query 4: Video Content\n",
        "\n",
        "Now let's ask a question from the Video."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Query requiring cross-modal integration\n",
        "cross_modal_query = \"What hapened in El Matador beach?\"\n",
        "\n",
        "cross_modal_response = query_kb(\n",
        "    query=cross_modal_query,\n",
        "    num_results=8  # Increase results to capture information from multiple modalities\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "In this notebook, we demonstrated how to build a Multimodal RAG application using Amazon Bedrock Data Automation and Bedrock Knowledge Bases. We covered the key steps:\n",
        "\n",
        "1. **Data Preparation**: We checked for existing BDA outputs or downloaded sample files\n",
        "2. **Knowledge Base Creation**: We created a Knowledge Base using real AWS API calls\n",
        "3. **Data Ingestion**: We ingested our multimodal data into the Knowledge Base\n",
        "4. **Querying**: We queried the Knowledge Base across different modalities using real AWS API calls\n",
        "\n",
        "This approach allows you to build powerful multimodal applications that can extract insights from different data types (documents, images, audio, and video) and provide unified access through natural language queries."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
